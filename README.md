# Toxic Comment Classification Using lstm
Multilabel, Multiclass classifcation probelm with model developed in keras. Data used here is from kaggle. Front end has been developed usign streamlit and App has been deployed using cloud run in GCP.

To use the deployed App please link on the link below :

https://lstm-app-joa4iuep3a-uc.a.run.app/

**Data description**:

We are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:

1.toxic

2.severe_toxic

3.obscene

4.threat

5.insult

6.identity_hate

Model here predicts a probability of each type of toxicity for each comment.
